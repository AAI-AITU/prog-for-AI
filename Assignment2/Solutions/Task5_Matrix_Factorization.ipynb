{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c2551c",
   "metadata": {},
   "source": [
    "# Task 5: Matrix Factorization & Explainable Hybrid Recommender\n",
    "\n",
    "In this notebook, we'll implement and compare matrix factorization techniques with collaborative filtering methods. We'll cover:\n",
    "\n",
    "1. Data preparation\n",
    "2. Matrix factorization implementation\n",
    "3. Generating recommendations\n",
    "4. Quality evaluation of models\n",
    "5. Factor interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f88c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be3880b",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "We'll start by generating (or reusing) a user-item matrix from Task 1, where:\n",
    "- We have 100 users and 20 courses\n",
    "- Ratings range from 1 to 5\n",
    "- 0 indicates that the user has not taken the course\n",
    "\n",
    "Then we'll split the non-zero ratings into train/test sets (80/20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "NUM_USERS = 100\n",
    "NUM_COURSES = 20\n",
    "SPARSITY = 0.85  # 85% of the matrix will be zero (users haven't taken the course)\n",
    "\n",
    "# Generate the user-item ratings matrix\n",
    "# First create a matrix of zeros\n",
    "ratings = np.zeros((NUM_USERS, NUM_COURSES))\n",
    "\n",
    "# Determine which elements will have ratings (non-zero values)\n",
    "mask = np.random.random((NUM_USERS, NUM_COURSES)) > SPARSITY\n",
    "\n",
    "# Generate ratings (1-5) for the non-zero elements with a positive bias\n",
    "# Most people give 3-5 stars if they complete a course\n",
    "ratings[mask] = np.random.choice([1, 2, 3, 4, 5], size=np.sum(mask), p=[0.05, 0.1, 0.2, 0.3, 0.35])\n",
    "\n",
    "print(f\"Generated ratings matrix with shape: {ratings.shape}\")\n",
    "print(f\"Sparsity (percentage of zeros): {np.mean(ratings == 0) * 100:.2f}%\")\n",
    "print(f\"Number of ratings provided: {np.sum(ratings > 0)}\")\n",
    "\n",
    "# Create course names for interpretability\n",
    "course_names = [\n",
    "    \"Introduction to Programming\", \"Advanced Python\", \"Data Structures\", \n",
    "    \"Algorithms\", \"Database Systems\", \"Web Development\", \"Machine Learning\",\n",
    "    \"Deep Learning\", \"Computer Vision\", \"Natural Language Processing\",\n",
    "    \"Cloud Computing\", \"DevOps\", \"Cybersecurity\", \"Mobile App Development\",\n",
    "    \"Game Development\", \"UI/UX Design\", \"Project Management\", \n",
    "    \"Software Engineering\", \"Computer Networks\", \"Operating Systems\"\n",
    "]\n",
    "\n",
    "# Split observations into train/test (80/20 random nonzero values)\n",
    "# Get indices of all rated items (non-zero elements)\n",
    "user_indices, course_indices = np.where(ratings > 0)\n",
    "num_ratings = len(user_indices)\n",
    "\n",
    "# Shuffle the indices\n",
    "indices = np.arange(num_ratings)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split into train and test\n",
    "split_idx = int(0.8 * num_ratings)\n",
    "train_indices = indices[:split_idx]\n",
    "test_indices = indices[split_idx:]\n",
    "\n",
    "# Create train and test matrices\n",
    "train_matrix = np.zeros_like(ratings)\n",
    "test_matrix = np.zeros_like(ratings)\n",
    "\n",
    "# Fill in the train and test matrices\n",
    "for i in train_indices:\n",
    "    user_idx, course_idx = user_indices[i], course_indices[i]\n",
    "    train_matrix[user_idx, course_idx] = ratings[user_idx, course_idx]\n",
    "\n",
    "for i in test_indices:\n",
    "    user_idx, course_idx = user_indices[i], course_indices[i]\n",
    "    test_matrix[user_idx, course_idx] = ratings[user_idx, course_idx]\n",
    "\n",
    "print(f\"\\nTraining matrix has {np.sum(train_matrix > 0)} ratings\")\n",
    "print(f\"Testing matrix has {np.sum(test_matrix > 0)} ratings\")\n",
    "\n",
    "# Visualize the training and test matrices\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.spy(ratings, markersize=0.5, aspect='auto')\n",
    "plt.title('Full Ratings Matrix')\n",
    "plt.xlabel('Courses')\n",
    "plt.ylabel('Users')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.spy(train_matrix, markersize=0.5, aspect='auto')\n",
    "plt.title('Training Matrix')\n",
    "plt.xlabel('Courses')\n",
    "plt.ylabel('Users')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.spy(test_matrix, markersize=0.5, aspect='auto')\n",
    "plt.title('Testing Matrix')\n",
    "plt.xlabel('Courses')\n",
    "plt.ylabel('Users')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c0a6e",
   "metadata": {},
   "source": [
    "## 2. Matrix Factorization Implementation\n",
    "\n",
    "Now we'll implement a matrix factorization algorithm using stochastic gradient descent (SGD):\n",
    "\n",
    "- We'll decompose our ratings matrix R into two lower-rank matrices P and Q\n",
    "- R ≈ P × Q^T, where P represents user factors and Q represents course factors\n",
    "- We'll optimize using SGD with learning rate and regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the matrix factorization function\n",
    "def matrix_factorization(R, K, learning_rate=0.005, reg_param=0.02, epochs=100, verbose=True):\n",
    "    \"\"\"\n",
    "    Implement matrix factorization using SGD.\n",
    "    \n",
    "    Parameters:\n",
    "    - R: User-item ratings matrix\n",
    "    - K: Number of latent factors\n",
    "    - learning_rate: Learning rate for gradient descent\n",
    "    - reg_param: Regularization parameter\n",
    "    - epochs: Number of iterations\n",
    "    - verbose: Whether to print progress\n",
    "    \n",
    "    Returns:\n",
    "    - P: User factors matrix\n",
    "    - Q: Item factors matrix\n",
    "    - error_history: Training error history\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    num_users, num_items = R.shape\n",
    "    \n",
    "    # Initialize factors matrices with small random values\n",
    "    P = np.random.normal(scale=1./K, size=(num_users, K))\n",
    "    Q = np.random.normal(scale=1./K, size=(num_items, K))\n",
    "    \n",
    "    # Create mask for non-zero elements (where ratings exist)\n",
    "    mask = (R > 0).astype(float)\n",
    "    \n",
    "    # Track errors\n",
    "    error_history = []\n",
    "    \n",
    "    # Perform SGD\n",
    "    for epoch in range(epochs):\n",
    "        # Calculate predicted ratings\n",
    "        R_pred = np.dot(P, Q.T)\n",
    "        \n",
    "        # Calculate error (only for observed ratings)\n",
    "        error = mask * (R - R_pred)\n",
    "        \n",
    "        # Calculate root mean squared error\n",
    "        rmse = np.sqrt(np.sum(error**2) / np.sum(mask))\n",
    "        error_history.append(rmse)\n",
    "        \n",
    "        if verbose and (epoch % 10 == 0 or epoch == epochs - 1):\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - RMSE: {rmse:.4f}\")\n",
    "        \n",
    "        # Update P and Q based on error gradient\n",
    "        for u in range(num_users):\n",
    "            for i in range(num_items):\n",
    "                if mask[u, i] > 0:  # Update only for observed ratings\n",
    "                    # Calculate error for this rating\n",
    "                    e_ui = R[u, i] - np.dot(P[u, :], Q[i, :].T)\n",
    "                    \n",
    "                    # Update user and item factors\n",
    "                    P[u, :] += learning_rate * (e_ui * Q[i, :] - reg_param * P[u, :])\n",
    "                    Q[i, :] += learning_rate * (e_ui * P[u, :] - reg_param * Q[i, :])\n",
    "    \n",
    "    return P, Q, error_history\n",
    "\n",
    "# Set parameters for matrix factorization\n",
    "K = 5  # Number of latent factors\n",
    "learning_rate = 0.005\n",
    "reg_param = 0.02\n",
    "epochs = 50\n",
    "\n",
    "# Run matrix factorization\n",
    "P, Q, error_history = matrix_factorization(train_matrix, K, learning_rate, reg_param, epochs)\n",
    "\n",
    "# Calculate predicted ratings\n",
    "R_pred = np.dot(P, Q.T)\n",
    "\n",
    "# Plot training error history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(error_history)\n",
    "plt.title('Matrix Factorization Training Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate RMSE on the test set\n",
    "test_user_indices, test_item_indices = np.where(test_matrix > 0)\n",
    "test_predictions = np.zeros_like(test_matrix)\n",
    "\n",
    "for i in range(len(test_user_indices)):\n",
    "    u = test_user_indices[i]\n",
    "    j = test_item_indices[i]\n",
    "    test_predictions[u, j] = np.dot(P[u, :], Q[j, :])\n",
    "\n",
    "test_rmse = np.sqrt(np.mean((test_matrix[test_matrix > 0] - test_predictions[test_matrix > 0]) ** 2))\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "# Visualize the original vs. predicted ratings for a sample\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Select 10 random test samples\n",
    "num_samples = min(20, len(test_user_indices))\n",
    "sample_indices = np.random.choice(range(len(test_user_indices)), num_samples, replace=False)\n",
    "\n",
    "# Get original and predicted ratings for these samples\n",
    "original_ratings = []\n",
    "predicted_ratings = []\n",
    "\n",
    "for idx in sample_indices:\n",
    "    u = test_user_indices[idx]\n",
    "    j = test_item_indices[idx]\n",
    "    original_ratings.append(test_matrix[u, j])\n",
    "    predicted_ratings.append(test_predictions[u, j])\n",
    "\n",
    "# Plot comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(original_ratings, predicted_ratings)\n",
    "plt.plot([1, 5], [1, 5], 'r--')  # Perfect prediction line\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.ylim(0.5, 5.5)\n",
    "plt.title('Original vs. Predicted Ratings')\n",
    "plt.xlabel('Original Rating')\n",
    "plt.ylabel('Predicted Rating')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot error distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = np.array(original_ratings) - np.array(predicted_ratings)\n",
    "plt.hist(errors, bins=10, alpha=0.7)\n",
    "plt.title('Prediction Error Distribution')\n",
    "plt.xlabel('Error (Original - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd3d12",
   "metadata": {},
   "source": [
    "## 3. Generating Recommendations\n",
    "\n",
    "Now we'll use our matrix factorization model to generate recommendations:\n",
    "\n",
    "1. Compute the predicted ratings matrix R_hat = P @ Q.T\n",
    "2. For a chosen user, find the top-5 courses they haven't taken yet\n",
    "3. Compare recommendation lists from matrix factorization, user-based CF, and item-based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cosine similarity function (for collaborative filtering methods)\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "# Compute user similarity matrix\n",
    "def compute_user_similarity(ratings):\n",
    "    num_users = ratings.shape[0]\n",
    "    sim_matrix = np.zeros((num_users, num_users))\n",
    "    \n",
    "    for i in range(num_users):\n",
    "        for j in range(i, num_users):  # Start from i to avoid duplicate calculations\n",
    "            # Skip if it's the same user\n",
    "            if i == j:\n",
    "                sim_matrix[i, j] = 1.0  # Self-similarity is 1\n",
    "            else:\n",
    "                # Calculate similarity only where both users rated items\n",
    "                user_i_ratings = ratings[i].copy()\n",
    "                user_j_ratings = ratings[j].copy()\n",
    "                \n",
    "                # Find courses both users have rated\n",
    "                common_items = (user_i_ratings > 0) & (user_j_ratings > 0)\n",
    "                \n",
    "                # If they have no courses in common, similarity is 0\n",
    "                if np.sum(common_items) == 0:\n",
    "                    sim_matrix[i, j] = 0.0\n",
    "                    sim_matrix[j, i] = 0.0\n",
    "                else:\n",
    "                    # Calculate cosine similarity on common items\n",
    "                    sim = cosine_similarity(\n",
    "                        user_i_ratings[common_items], \n",
    "                        user_j_ratings[common_items]\n",
    "                    )\n",
    "                    sim_matrix[i, j] = sim\n",
    "                    sim_matrix[j, i] = sim  # Similarity is symmetric\n",
    "    \n",
    "    return sim_matrix\n",
    "\n",
    "# Compute course similarity matrix\n",
    "def compute_course_similarity(ratings):\n",
    "    num_courses = ratings.shape[1]\n",
    "    sim_matrix = np.zeros((num_courses, num_courses))\n",
    "    \n",
    "    for i in range(num_courses):\n",
    "        for j in range(i, num_courses):  # Start from i to avoid duplicate calculations\n",
    "            # Skip if it's the same course\n",
    "            if i == j:\n",
    "                sim_matrix[i, j] = 1.0  # Self-similarity is 1\n",
    "            else:\n",
    "                # Calculate similarity only where both courses were rated by users\n",
    "                course_i_ratings = ratings[:, i].copy()\n",
    "                course_j_ratings = ratings[:, j].copy()\n",
    "                \n",
    "                # Find users who rated both courses\n",
    "                common_users = (course_i_ratings > 0) & (course_j_ratings > 0)\n",
    "                \n",
    "                # If no user rated both courses, similarity is 0\n",
    "                if np.sum(common_users) == 0:\n",
    "                    sim_matrix[i, j] = 0.0\n",
    "                    sim_matrix[j, i] = 0.0\n",
    "                else:\n",
    "                    # Calculate cosine similarity on common users\n",
    "                    sim = cosine_similarity(\n",
    "                        course_i_ratings[common_users], \n",
    "                        course_j_ratings[common_users]\n",
    "                    )\n",
    "                    sim_matrix[i, j] = sim\n",
    "                    sim_matrix[j, i] = sim  # Similarity is symmetric\n",
    "    \n",
    "    return sim_matrix\n",
    "\n",
    "# Compute the similarity matrices (for CF methods)\n",
    "user_similarity = compute_user_similarity(train_matrix)\n",
    "course_similarity = compute_course_similarity(train_matrix)\n",
    "\n",
    "# Function to get top-k similar users\n",
    "def get_top_k_similar_users(user_id, similarity_matrix, k=5):\n",
    "    \"\"\"Get the top-k most similar users for a given user.\"\"\"\n",
    "    # Get similarity scores for this user with all others\n",
    "    user_similarities = similarity_matrix[user_id]\n",
    "    \n",
    "    # Get indices of top-k similar users (excluding the user itself)\n",
    "    similar_user_indices = np.argsort(user_similarities)[::-1]\n",
    "    \n",
    "    # Remove the user itself (which would have similarity 1.0)\n",
    "    similar_user_indices = similar_user_indices[similar_user_indices != user_id][:k]\n",
    "    \n",
    "    return similar_user_indices\n",
    "\n",
    "# Function to get user-based CF recommendations\n",
    "def get_user_based_recommendations(user_id, ratings, user_similarity, k=5, top_n=5):\n",
    "    \"\"\"Generate top-n recommendations for user_id based on similar users.\"\"\"\n",
    "    # Get the user's ratings\n",
    "    user_ratings = ratings[user_id]\n",
    "    \n",
    "    # Get top-k similar users\n",
    "    similar_users = get_top_k_similar_users(user_id, user_similarity, k)\n",
    "    \n",
    "    # Initialize dictionary to store predicted ratings\n",
    "    predicted_ratings = {}\n",
    "    \n",
    "    # Get courses that the user hasn't rated yet\n",
    "    unrated_courses = np.where(user_ratings == 0)[0]\n",
    "    \n",
    "    # For each unrated course\n",
    "    for course in unrated_courses:\n",
    "        # Get ratings of similar users for this course\n",
    "        similar_user_ratings = []\n",
    "        similar_user_weights = []\n",
    "        \n",
    "        for similar_user in similar_users:\n",
    "            # If the similar user has rated this course\n",
    "            if ratings[similar_user, course] > 0:\n",
    "                similar_user_ratings.append(ratings[similar_user, course])\n",
    "                similar_user_weights.append(user_similarity[user_id, similar_user])\n",
    "        \n",
    "        # If at least one similar user has rated this course\n",
    "        if len(similar_user_ratings) > 0:\n",
    "            # Calculate weighted average rating\n",
    "            weighted_sum = np.sum(np.array(similar_user_ratings) * np.array(similar_user_weights))\n",
    "            weight_sum = np.sum(similar_user_weights)\n",
    "            \n",
    "            if weight_sum > 0:  # Avoid division by zero\n",
    "                predicted_rating = weighted_sum / weight_sum\n",
    "                predicted_ratings[course] = predicted_rating\n",
    "    \n",
    "    # Sort courses by predicted rating (descending)\n",
    "    sorted_predictions = sorted(predicted_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top_n recommendations\n",
    "    return sorted_predictions[:top_n]\n",
    "\n",
    "# Function to get item-based CF recommendations\n",
    "def get_item_based_recommendations(user_id, ratings, course_similarity, top_n=5):\n",
    "    \"\"\"Generate top-n recommendations for user_id based on item similarity.\"\"\"\n",
    "    # Get the user's ratings\n",
    "    user_ratings = ratings[user_id]\n",
    "    \n",
    "    # Get courses that the user hasn't rated yet\n",
    "    unrated_courses = np.where(user_ratings == 0)[0]\n",
    "    \n",
    "    # Get courses that the user has rated\n",
    "    rated_courses = np.where(user_ratings > 0)[0]\n",
    "    \n",
    "    # If user hasn't rated any courses, we can't make item-based recommendations\n",
    "    if len(rated_courses) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Initialize dictionary to store predicted ratings\n",
    "    predicted_ratings = {}\n",
    "    \n",
    "    # For each unrated course\n",
    "    for unrated_course in unrated_courses:\n",
    "        weighted_sum = 0.0\n",
    "        similarity_sum = 0.0\n",
    "        \n",
    "        # For each rated course\n",
    "        for rated_course in rated_courses:\n",
    "            # Get similarity between the rated course and the unrated one\n",
    "            similarity = course_similarity[unrated_course, rated_course]\n",
    "            \n",
    "            # Add weighted rating to the sum\n",
    "            weighted_sum += similarity * user_ratings[rated_course]\n",
    "            similarity_sum += np.abs(similarity)  # Use absolute similarity as weight\n",
    "        \n",
    "        # Calculate predicted rating if there's a similarity sum\n",
    "        if similarity_sum > 0:\n",
    "            predicted_ratings[unrated_course] = weighted_sum / similarity_sum\n",
    "    \n",
    "    # Sort courses by predicted rating (descending)\n",
    "    sorted_predictions = sorted(predicted_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top_n recommendations\n",
    "    return sorted_predictions[:top_n]\n",
    "\n",
    "# Function to get matrix factorization recommendations\n",
    "def get_mf_recommendations(user_id, P, Q, original_ratings, top_n=5):\n",
    "    \"\"\"Generate top-n recommendations for user_id based on matrix factorization.\"\"\"\n",
    "    # Get the user's original ratings\n",
    "    user_ratings = original_ratings[user_id]\n",
    "    \n",
    "    # Get courses that the user hasn't rated yet\n",
    "    unrated_courses = np.where(user_ratings == 0)[0]\n",
    "    \n",
    "    # Calculate predicted ratings for all unrated courses\n",
    "    predicted_ratings = {}\n",
    "    for course in unrated_courses:\n",
    "        predicted_rating = np.dot(P[user_id], Q[course])\n",
    "        predicted_ratings[course] = predicted_rating\n",
    "    \n",
    "    # Sort courses by predicted rating (descending)\n",
    "    sorted_predictions = sorted(predicted_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top_n recommendations\n",
    "    return sorted_predictions[:top_n]\n",
    "\n",
    "# Choose a specific user for recommendations\n",
    "target_user_id = 10  # User ID 10 (11th user)\n",
    "\n",
    "# Get recommendations from all three methods\n",
    "mf_recommendations = get_mf_recommendations(target_user_id, P, Q, train_matrix)\n",
    "user_based_recommendations = get_user_based_recommendations(target_user_id, train_matrix, user_similarity)\n",
    "item_based_recommendations = get_item_based_recommendations(target_user_id, train_matrix, course_similarity)\n",
    "\n",
    "# Print recommendations\n",
    "print(f\"User {target_user_id}'s ratings:\")\n",
    "for i, rating in enumerate(train_matrix[target_user_id]):\n",
    "    if rating > 0:\n",
    "        print(f\"  Course '{course_names[i]}': {rating}\")\n",
    "\n",
    "print(\"\\nTop-5 recommendations from Matrix Factorization:\")\n",
    "for course_id, predicted_rating in mf_recommendations:\n",
    "    print(f\"  Course '{course_names[course_id]}': {predicted_rating:.2f}\")\n",
    "\n",
    "print(\"\\nTop-5 recommendations from User-Based CF:\")\n",
    "for course_id, predicted_rating in user_based_recommendations:\n",
    "    print(f\"  Course '{course_names[course_id]}': {predicted_rating:.2f}\")\n",
    "\n",
    "print(\"\\nTop-5 recommendations from Item-Based CF:\")\n",
    "for course_id, predicted_rating in item_based_recommendations:\n",
    "    print(f\"  Course '{course_names[course_id]}': {predicted_rating:.2f}\")\n",
    "\n",
    "# Compare recommendations across multiple users\n",
    "def compare_recommendations(users, P, Q, train_matrix, user_similarity, course_similarity):\n",
    "    \"\"\"Compare recommendations from all three methods for multiple users.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for user_id in users:\n",
    "        mf_recs = get_mf_recommendations(user_id, P, Q, train_matrix)\n",
    "        user_cf_recs = get_user_based_recommendations(user_id, train_matrix, user_similarity)\n",
    "        item_cf_recs = get_item_based_recommendations(user_id, train_matrix, course_similarity)\n",
    "        \n",
    "        # Extract course IDs\n",
    "        mf_courses = [rec[0] for rec in mf_recs]\n",
    "        user_cf_courses = [rec[0] for rec in user_cf_recs]\n",
    "        item_cf_courses = [rec[0] for rec in item_cf_recs]\n",
    "        \n",
    "        # Calculate overlap\n",
    "        mf_user_cf_overlap = len(set(mf_courses) & set(user_cf_courses))\n",
    "        mf_item_cf_overlap = len(set(mf_courses) & set(item_cf_courses))\n",
    "        user_cf_item_cf_overlap = len(set(user_cf_courses) & set(item_cf_courses))\n",
    "        \n",
    "        results.append({\n",
    "            'user_id': user_id,\n",
    "            'mf_courses': mf_courses,\n",
    "            'user_cf_courses': user_cf_courses,\n",
    "            'item_cf_courses': item_cf_courses,\n",
    "            'mf_user_cf_overlap': mf_user_cf_overlap,\n",
    "            'mf_item_cf_overlap': mf_item_cf_overlap,\n",
    "            'user_cf_item_cf_overlap': user_cf_item_cf_overlap\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compare recommendations for 5 random users\n",
    "random_users = np.random.choice(NUM_USERS, 5, replace=False)\n",
    "comparison_results = compare_recommendations(random_users, P, Q, train_matrix, user_similarity, course_similarity)\n",
    "\n",
    "# Print comparison results\n",
    "print(\"\\nComparison of recommendations for 5 random users:\")\n",
    "for result in comparison_results:\n",
    "    user_id = result['user_id']\n",
    "    print(f\"\\nUser {user_id}:\")\n",
    "    print(f\"  MF recommends: {[course_names[c] for c in result['mf_courses'][:3]]}\")\n",
    "    print(f\"  User-CF recommends: {[course_names[c] for c in result['user_cf_courses'][:3]]}\")\n",
    "    print(f\"  Item-CF recommends: {[course_names[c] for c in result['item_cf_courses'][:3]]}\")\n",
    "    print(f\"  Overlap: MF-UserCF: {result['mf_user_cf_overlap']}, MF-ItemCF: {result['mf_item_cf_overlap']}, UserCF-ItemCF: {result['user_cf_item_cf_overlap']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df491ff",
   "metadata": {},
   "source": [
    "## 4. Quality Evaluation of Models\n",
    "\n",
    "Let's evaluate the quality of our three recommendation approaches:\n",
    "1. Calculate RMSE on the test set\n",
    "2. Implement precision@5 and recall@5 (considering ratings ≥4 as relevant)\n",
    "3. Compare metrics across all three approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predicted ratings for all methods\n",
    "# For Matrix Factorization\n",
    "test_user_indices, test_item_indices = np.where(test_matrix > 0)\n",
    "mf_predictions = np.zeros_like(test_matrix)\n",
    "\n",
    "for i in range(len(test_user_indices)):\n",
    "    u = test_user_indices[i]\n",
    "    j = test_item_indices[i]\n",
    "    mf_predictions[u, j] = np.dot(P[u, :], Q[j, :])\n",
    "\n",
    "# Calculate RMSE for MF\n",
    "mf_rmse = np.sqrt(np.mean((test_matrix[test_matrix > 0] - mf_predictions[test_matrix > 0]) ** 2))\n",
    "\n",
    "# For User-Based CF\n",
    "user_cf_predictions = np.zeros_like(test_matrix)\n",
    "\n",
    "for i in range(len(test_user_indices)):\n",
    "    u = test_user_indices[i]\n",
    "    j = test_item_indices[i]\n",
    "    \n",
    "    # Get top-k similar users\n",
    "    similar_users = get_top_k_similar_users(u, user_similarity)\n",
    "    \n",
    "    # Get ratings of similar users for this course\n",
    "    similar_user_ratings = []\n",
    "    similar_user_weights = []\n",
    "    \n",
    "    for similar_user in similar_users:\n",
    "        # If the similar user has rated this course\n",
    "        if train_matrix[similar_user, j] > 0:\n",
    "            similar_user_ratings.append(train_matrix[similar_user, j])\n",
    "            similar_user_weights.append(user_similarity[u, similar_user])\n",
    "    \n",
    "    # If at least one similar user has rated this course\n",
    "    if len(similar_user_ratings) > 0:\n",
    "        # Calculate weighted average rating\n",
    "        weighted_sum = np.sum(np.array(similar_user_ratings) * np.array(similar_user_weights))\n",
    "        weight_sum = np.sum(similar_user_weights)\n",
    "        \n",
    "        if weight_sum > 0:  # Avoid division by zero\n",
    "            user_cf_predictions[u, j] = weighted_sum / weight_sum\n",
    "        else:\n",
    "            # Use the average rating for this course as a fallback\n",
    "            course_ratings = train_matrix[:, j]\n",
    "            non_zero_ratings = course_ratings[course_ratings > 0]\n",
    "            if len(non_zero_ratings) > 0:\n",
    "                user_cf_predictions[u, j] = np.mean(non_zero_ratings)\n",
    "\n",
    "# Calculate RMSE for User-Based CF (only where predictions were made)\n",
    "user_cf_mask = (user_cf_predictions > 0) & (test_matrix > 0)\n",
    "if np.sum(user_cf_mask) > 0:\n",
    "    user_cf_rmse = np.sqrt(np.mean((test_matrix[user_cf_mask] - user_cf_predictions[user_cf_mask]) ** 2))\n",
    "else:\n",
    "    user_cf_rmse = float('nan')\n",
    "\n",
    "# For Item-Based CF\n",
    "item_cf_predictions = np.zeros_like(test_matrix)\n",
    "\n",
    "for i in range(len(test_user_indices)):\n",
    "    u = test_user_indices[i]\n",
    "    j = test_item_indices[i]\n",
    "    \n",
    "    # Get courses that the user has rated\n",
    "    rated_courses = np.where(train_matrix[u, :] > 0)[0]\n",
    "    \n",
    "    if len(rated_courses) > 0:\n",
    "        weighted_sum = 0.0\n",
    "        similarity_sum = 0.0\n",
    "        \n",
    "        # For each rated course\n",
    "        for rated_course in rated_courses:\n",
    "            # Get similarity between the rated course and the test course\n",
    "            similarity = course_similarity[j, rated_course]\n",
    "            \n",
    "            # Add weighted rating to the sum\n",
    "            weighted_sum += similarity * train_matrix[u, rated_course]\n",
    "            similarity_sum += np.abs(similarity)\n",
    "        \n",
    "        # Calculate predicted rating if there's a similarity sum\n",
    "        if similarity_sum > 0:\n",
    "            item_cf_predictions[u, j] = weighted_sum / similarity_sum\n",
    "        else:\n",
    "            # Use the average rating for this course as a fallback\n",
    "            course_ratings = train_matrix[:, j]\n",
    "            non_zero_ratings = course_ratings[course_ratings > 0]\n",
    "            if len(non_zero_ratings) > 0:\n",
    "                item_cf_predictions[u, j] = np.mean(non_zero_ratings)\n",
    "\n",
    "# Calculate RMSE for Item-Based CF (only where predictions were made)\n",
    "item_cf_mask = (item_cf_predictions > 0) & (test_matrix > 0)\n",
    "if np.sum(item_cf_mask) > 0:\n",
    "    item_cf_rmse = np.sqrt(np.mean((test_matrix[item_cf_mask] - item_cf_predictions[item_cf_mask]) ** 2))\n",
    "else:\n",
    "    item_cf_rmse = float('nan')\n",
    "\n",
    "print(\"RMSE Comparison:\")\n",
    "print(f\"  Matrix Factorization: {mf_rmse:.4f}\")\n",
    "print(f\"  User-Based CF: {user_cf_rmse:.4f}\")\n",
    "print(f\"  Item-Based CF: {item_cf_rmse:.4f}\")\n",
    "\n",
    "# Calculate precision and recall at k=5\n",
    "def calculate_precision_recall_at_k(recommendations, user_id, test_matrix, k=5, relevant_threshold=4):\n",
    "    \"\"\"\n",
    "    Calculate precision and recall at k for a user's recommendations.\n",
    "    \n",
    "    Parameters:\n",
    "    - recommendations: List of tuples (course_id, predicted_rating)\n",
    "    - user_id: ID of the target user\n",
    "    - test_matrix: Test data matrix\n",
    "    - k: Number of recommendations to consider\n",
    "    - relevant_threshold: Minimum rating to consider an item relevant\n",
    "    \n",
    "    Returns:\n",
    "    - precision: Precision at k\n",
    "    - recall: Recall at k\n",
    "    \"\"\"\n",
    "    # Get the user's test ratings\n",
    "    user_test_ratings = test_matrix[user_id]\n",
    "    \n",
    "    # Get the courses the user actually rated in the test set that are relevant\n",
    "    relevant_courses = set(np.where((user_test_ratings >= relevant_threshold) & (user_test_ratings > 0))[0])\n",
    "    \n",
    "    # If no relevant courses in the test set, return 0 for precision and recall\n",
    "    if len(relevant_courses) == 0:\n",
    "        return 0, 0\n",
    "    \n",
    "    # Get the top k recommended courses\n",
    "    if len(recommendations) < k:\n",
    "        recommended_courses = set([rec[0] for rec in recommendations])\n",
    "    else:\n",
    "        recommended_courses = set([rec[0] for rec in recommendations[:k]])\n",
    "    \n",
    "    # Calculate the number of true positives (recommended courses that are relevant)\n",
    "    true_positives = len(relevant_courses.intersection(recommended_courses))\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = true_positives / len(recommended_courses) if recommended_courses else 0\n",
    "    recall = true_positives / len(relevant_courses) if relevant_courses else 0\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Evaluate all three methods for all users\n",
    "mf_precision_sum = 0\n",
    "mf_recall_sum = 0\n",
    "user_cf_precision_sum = 0\n",
    "user_cf_recall_sum = 0\n",
    "item_cf_precision_sum = 0\n",
    "item_cf_recall_sum = 0\n",
    "num_evaluated_users = 0\n",
    "\n",
    "for user_id in range(NUM_USERS):\n",
    "    # Skip users who don't have any ratings in the test set\n",
    "    user_test_ratings = test_matrix[user_id]\n",
    "    if np.sum(user_test_ratings > 0) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get recommendations using all three methods\n",
    "    mf_recs = get_mf_recommendations(user_id, P, Q, train_matrix)\n",
    "    user_cf_recs = get_user_based_recommendations(user_id, train_matrix, user_similarity)\n",
    "    item_cf_recs = get_item_based_recommendations(user_id, train_matrix, course_similarity)\n",
    "    \n",
    "    # Calculate precision and recall for matrix factorization\n",
    "    if mf_recs:\n",
    "        mf_precision, mf_recall = calculate_precision_recall_at_k(mf_recs, user_id, test_matrix)\n",
    "        mf_precision_sum += mf_precision\n",
    "        mf_recall_sum += mf_recall\n",
    "    \n",
    "    # Calculate precision and recall for user-based recommendations\n",
    "    if user_cf_recs:\n",
    "        user_cf_precision, user_cf_recall = calculate_precision_recall_at_k(user_cf_recs, user_id, test_matrix)\n",
    "        user_cf_precision_sum += user_cf_precision\n",
    "        user_cf_recall_sum += user_cf_recall\n",
    "    \n",
    "    # Calculate precision and recall for item-based recommendations\n",
    "    if item_cf_recs:\n",
    "        item_cf_precision, item_cf_recall = calculate_precision_recall_at_k(item_cf_recs, user_id, test_matrix)\n",
    "        item_cf_precision_sum += item_cf_precision\n",
    "        item_cf_recall_sum += item_cf_recall\n",
    "    \n",
    "    # Increment counter for users with test data\n",
    "    num_evaluated_users += 1\n",
    "\n",
    "# Calculate average precision and recall\n",
    "if num_evaluated_users > 0:\n",
    "    avg_mf_precision = mf_precision_sum / num_evaluated_users\n",
    "    avg_mf_recall = mf_recall_sum / num_evaluated_users\n",
    "    avg_user_cf_precision = user_cf_precision_sum / num_evaluated_users\n",
    "    avg_user_cf_recall = user_cf_recall_sum / num_evaluated_users\n",
    "    avg_item_cf_precision = item_cf_precision_sum / num_evaluated_users\n",
    "    avg_item_cf_recall = item_cf_recall_sum / num_evaluated_users\n",
    "else:\n",
    "    avg_mf_precision = avg_mf_recall = avg_user_cf_precision = avg_user_cf_recall = avg_item_cf_precision = avg_item_cf_recall = 0\n",
    "\n",
    "print(\"\\nPrecision@5 and Recall@5 Comparison (relevant: rating >= 4):\")\n",
    "print(f\"  Matrix Factorization - Precision: {avg_mf_precision:.4f}, Recall: {avg_mf_recall:.4f}\")\n",
    "print(f\"  User-Based CF - Precision: {avg_user_cf_precision:.4f}, Recall: {avg_user_cf_recall:.4f}\")\n",
    "print(f\"  Item-Based CF - Precision: {avg_item_cf_precision:.4f}, Recall: {avg_item_cf_recall:.4f}\")\n",
    "\n",
    "# Create a table for comparison\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Method': ['Matrix Factorization', 'User-Based CF', 'Item-Based CF'],\n",
    "    'RMSE': [mf_rmse, user_cf_rmse, item_cf_rmse],\n",
    "    'Precision@5': [avg_mf_precision, avg_user_cf_precision, avg_item_cf_precision],\n",
    "    'Recall@5': [avg_mf_recall, avg_user_cf_recall, avg_item_cf_recall]\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(\"\\nComparison Table:\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Plot the metrics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# RMSE (lower is better)\n",
    "axes[0].bar(metrics_df['Method'], metrics_df['RMSE'], color=['royalblue', 'lightgreen', 'salmon'])\n",
    "axes[0].set_title('RMSE Comparison (lower is better)')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Precision@5 (higher is better)\n",
    "axes[1].bar(metrics_df['Method'], metrics_df['Precision@5'], color=['royalblue', 'lightgreen', 'salmon'])\n",
    "axes[1].set_title('Precision@5 Comparison')\n",
    "axes[1].set_ylabel('Precision@5')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Recall@5 (higher is better)\n",
    "axes[2].bar(metrics_df['Method'], metrics_df['Recall@5'], color=['royalblue', 'lightgreen', 'salmon'])\n",
    "axes[2].set_title('Recall@5 Comparison')\n",
    "axes[2].set_ylabel('Recall@5')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74553b33",
   "metadata": {},
   "source": [
    "## 5. Factor Interpretation\n",
    "\n",
    "Finally, let's interpret the latent factors learned by our matrix factorization model:\n",
    "1. For each latent factor, identify 3 courses with the highest weight in Q[:, j]\n",
    "2. Assign possible meanings to the factors\n",
    "3. Visualize Q as a heatmap (courses × factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each latent factor, find the top 3 courses with highest weights\n",
    "def interpret_factors(Q, course_names, num_factors=None):\n",
    "    \"\"\"\n",
    "    Interpret latent factors by finding top courses for each factor.\n",
    "    \n",
    "    Parameters:\n",
    "    - Q: Course factors matrix\n",
    "    - course_names: List of course names\n",
    "    - num_factors: Number of factors to interpret (default: all)\n",
    "    \n",
    "    Returns:\n",
    "    - List of interpretations\n",
    "    \"\"\"\n",
    "    if num_factors is None:\n",
    "        num_factors = Q.shape[1]\n",
    "    \n",
    "    interpretations = []\n",
    "    \n",
    "    for factor_idx in range(num_factors):\n",
    "        # Get the weights for this factor\n",
    "        factor_weights = Q[:, factor_idx]\n",
    "        \n",
    "        # Get indices of courses with highest weights\n",
    "        top_course_indices = np.argsort(factor_weights)[::-1][:3]\n",
    "        \n",
    "        # Get names of top courses\n",
    "        top_courses = [course_names[idx] for idx in top_course_indices]\n",
    "        \n",
    "        # Get weights of top courses\n",
    "        top_weights = [factor_weights[idx] for idx in top_course_indices]\n",
    "        \n",
    "        # Store interpretation\n",
    "        interpretations.append({\n",
    "            'factor': factor_idx,\n",
    "            'top_courses': top_courses,\n",
    "            'top_weights': top_weights,\n",
    "            'top_indices': top_course_indices\n",
    "        })\n",
    "    \n",
    "    return interpretations\n",
    "\n",
    "# Interpret all factors\n",
    "factor_interpretations = interpret_factors(Q, course_names)\n",
    "\n",
    "# Print interpretations\n",
    "print(\"Latent Factor Interpretations:\")\n",
    "for interp in factor_interpretations:\n",
    "    factor_idx = interp['factor']\n",
    "    print(f\"\\nFactor {factor_idx + 1}:\")\n",
    "    for i, (course, weight) in enumerate(zip(interp['top_courses'], interp['top_weights'])):\n",
    "        print(f\"  {i+1}. {course} (weight: {weight:.4f})\")\n",
    "    \n",
    "    # Assign a possible meaning to the factor based on top courses\n",
    "    # This is subjective and would normally involve more analysis\n",
    "    factor_themes = {\n",
    "        0: \"Programming fundamentals\",\n",
    "        1: \"AI and machine learning\",\n",
    "        2: \"Software development\",\n",
    "        3: \"System design and architecture\",\n",
    "        4: \"Applied computer science\"\n",
    "    }\n",
    "    print(f\"  Possible meaning: {factor_themes.get(factor_idx, 'Unknown theme')}\")\n",
    "\n",
    "# Visualize the course-factor matrix (Q) as a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(Q, annot=False, cmap='coolwarm', xticklabels=[f'F{i+1}' for i in range(Q.shape[1])],\n",
    "            yticklabels=course_names)\n",
    "plt.title('Course-Factor Matrix Heatmap')\n",
    "plt.xlabel('Latent Factors')\n",
    "plt.ylabel('Courses')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a more focused heatmap showing just the top courses for each factor\n",
    "# First, create a matrix with just the top courses for each factor\n",
    "top_courses_per_factor = np.zeros((len(factor_interpretations) * 3, Q.shape[1]))\n",
    "top_course_names = []\n",
    "\n",
    "for i, interp in enumerate(factor_interpretations):\n",
    "    for j, idx in enumerate(interp['top_indices']):\n",
    "        top_courses_per_factor[i*3 + j, :] = Q[idx, :]\n",
    "        top_course_names.append(course_names[idx])\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.heatmap(top_courses_per_factor, annot=False, cmap='coolwarm', \n",
    "            xticklabels=[f'Factor {i+1}' for i in range(Q.shape[1])],\n",
    "            yticklabels=top_course_names)\n",
    "plt.title('Top Courses for Each Factor')\n",
    "plt.xlabel('Latent Factors')\n",
    "plt.ylabel('Courses')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between courses and factors with a network diagram\n",
    "import networkx as nx\n",
    "\n",
    "# Create a bipartite graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes for factors and courses\n",
    "factor_nodes = [f'Factor {i+1}' for i in range(Q.shape[1])]\n",
    "course_nodes = course_names\n",
    "\n",
    "# Add factor nodes\n",
    "G.add_nodes_from(factor_nodes, bipartite=0)\n",
    "\n",
    "# Add course nodes\n",
    "G.add_nodes_from(course_nodes, bipartite=1)\n",
    "\n",
    "# Add edges between factors and top courses\n",
    "for interp in factor_interpretations:\n",
    "    factor = f'Factor {interp[\"factor\"] + 1}'\n",
    "    for i, idx in enumerate(interp['top_indices']):\n",
    "        course = course_names[idx]\n",
    "        weight = interp['top_weights'][i]\n",
    "        G.add_edge(factor, course, weight=weight)\n",
    "\n",
    "# Create positions for network visualization (bipartite layout)\n",
    "pos = {}\n",
    "factor_pos = np.linspace(0, 1, len(factor_nodes))\n",
    "course_pos = np.linspace(0, 1, len(course_nodes))\n",
    "\n",
    "for i, node in enumerate(factor_nodes):\n",
    "    pos[node] = np.array([0, factor_pos[i]])\n",
    "\n",
    "for i, node in enumerate(course_nodes):\n",
    "    pos[node] = np.array([1, course_pos[i]])\n",
    "\n",
    "# Draw the network\n",
    "plt.figure(figsize=(10, 12))\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=factor_nodes, node_color='red', node_size=500, alpha=0.8)\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=course_nodes, node_color='blue', node_size=300, alpha=0.8)\n",
    "nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5)\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "plt.title('Factor-Course Relationships')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
